{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "864e3c9e",
   "metadata": {},
   "source": [
    "<table border=\"0\" style=\"width:100%\">\n",
    " <tr>\n",
    "    <td>\n",
    "        <img src=\"https://static-frm.ie.edu/university/wp-content/uploads/sites/6/2022/06/IE-University-logo.png\" width=150>\n",
    "     </td>\n",
    "    <td><div style=\"font-family:'Courier New'\">\n",
    "            <div style=\"font-size:25px\">\n",
    "                <div style=\"text-align: right\"> \n",
    "                    <b> MASTER IN BIG DATA</b>\n",
    "                    <br>\n",
    "                    Python for Data Analysis II\n",
    "                    <br><br>\n",
    "                    <em> Daniel Sierra Ramos </em>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </td>\n",
    " </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a8713b3-4653-416d-8a39-48756477e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import zipfile\n",
    "import geopandas\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ea61b73",
   "metadata": {},
   "source": [
    "## **Streamlit** App with Uber data\n",
    "\n",
    "Build a Streamlit app to represent some charts about using public Uber data. This data contains information about the average travel time of Uber rides between all neighborhoods in MAdrid city.\n",
    "\n",
    "The app must have the following characteristics\n",
    " - Main frame must show 3 charts given a `SOURCE` and `DESTINATION`:\n",
    "    1. Time series of the average travel time\n",
    "    2. Bar chart of the average travel time for every weekday, and period of the day\n",
    "    3. **(Optional)** Choropleth map of Madrid city, with the source and destination highlighted\n",
    " - A side bar containing two box selectors to select the `SOURCE` and `DESTINATION`\n",
    " - Every time a source or a destination is selected, the charts of the main frame should be updated accordingly.\n",
    "\n",
    " NOTE: I recommend you to build the charts first here in the notebook, and then copy the code to the Streamlit app."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f1a1402",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Use the following function to load the data. For the first two figures you will need just the `data` variable. For the choropleth map you will need the `codes` variable and the `geopandas` library to work with maps (this is optional). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f638a510",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def read_and_preprocess_data():\n",
    "    \n",
    "    with zipfile.ZipFile('data/uber-data.zip') as zip:\n",
    "        with zip.open('madrid-barrios-2020-1-All-DatesByHourBucketsAggregate.csv') as csv:\n",
    "            data = pd.read_csv(csv)\n",
    "        with zip.open('madrid_barrios.json') as geojson:\n",
    "            codes = geopandas.read_file(geojson, encoding=\"utf-8\")\n",
    "\n",
    "    # change data types in codes because they are not the same as in data\n",
    "    codes['GEOCODIGO'] = codes['GEOCODIGO'].astype(int)\n",
    "    codes['MOVEMENT_ID'] = codes['MOVEMENT_ID'].astype(int)\n",
    "\n",
    "    codes[\"DISPLAY_NAME\"] = codes[\"DISPLAY_NAME\"].str.split().str[1:].str.join(\" \")\n",
    "\n",
    "    # Merge the data with the codes (source)\n",
    "    data = data.merge(codes[[\"GEOCODIGO\",\"MOVEMENT_ID\",\"DISPLAY_NAME\"]], left_on=\"sourceid\", right_on=\"MOVEMENT_ID\", how=\"left\")\n",
    "    data = data.rename(columns={\"GEOCODIGO\":\"src_neigh_code\", \"DISPLAY_NAME\":\"src_neigh_name\"}).drop(columns=[\"MOVEMENT_ID\"])\n",
    "\n",
    "    data = data.merge(codes[[\"GEOCODIGO\",\"MOVEMENT_ID\",\"DISPLAY_NAME\"]], left_on=\"dstid\", right_on=\"MOVEMENT_ID\", how=\"left\")\n",
    "    data = data.rename(columns={\"GEOCODIGO\":\"dst_neigh_code\", \"DISPLAY_NAME\":\"dst_neigh_name\"}).drop(columns=[\"MOVEMENT_ID\"])\n",
    "\n",
    "    # Create a new date column\n",
    "    data[\"year\"] = \"2020\"\n",
    "    data[\"date\"] = pd.to_datetime(data[\"day\"].astype(str)+data[\"month\"].astype(str)+data[\"year\"].astype(str)+\":\"+data[\"start_hour\"].astype(str), format=\"%d%m%Y:%H\")\n",
    "\n",
    "    # Create a new day_period column\n",
    "    data[\"day_period\"] = data.start_hour.astype(str) + \"-\" + data.end_hour.astype(str)\n",
    "    data[\"day_of_week\"] = data.date.dt.weekday\n",
    "    data[\"day_of_week_str\"] = data.date.dt.day_name()\n",
    "\n",
    "    return data, codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213cc9a9",
   "metadata": {},
   "source": [
    "### Travel by Time and Day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302e4346",
   "metadata": {},
   "source": [
    "### Travel by Time and Day Period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c62e1dd",
   "metadata": {},
   "source": [
    "### Map between source and destination"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yaba_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "969199f905ecf0b6d7c5b1244082a299a8e6d6ba9e1d12402d430be44e50efca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
